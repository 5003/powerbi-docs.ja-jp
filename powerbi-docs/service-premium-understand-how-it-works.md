---
title: Power BI Premium 容量のメモリの使用と最適化
description: Power BI Premium 容量のメモリの管理と最適化について説明します。
ms.date: 04/30/2018
ms.topic: conceptual
ms.service: powerbi
ms.component: powerbi-admin
ms.author: susuresh
ms.reviewer: susuresh
author: suds001
manager: kfile
ms.openlocfilehash: 03c5e56c5f516bb1f09f51463d4c533185fbb63c
ms.sourcegitcommit: 80d6b45eb84243e801b60b9038b9bff77c30d5c8
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/04/2018
ms.locfileid: "34298460"
---
# <a name="power-bi-premium-capacity-resource-management-and-optimization"></a>Power BI Premium 容量のリソースの管理と最適化

この記事では、Power BI Premium サービスがリソースを管理する方法を説明し、ソリューションの計画と最適化に関するヒントを示します。

## <a name="premium-capacity-memory-management"></a>Premium 容量のメモリ管理

 Premium 容量は次のものによって消費されます。

* 読み込まれたデータセットによって使われるメモリ
* データセットの更新によって使われるメモリ (スケジュールとオンデマンドの両方)
* レポートのクエリによって使われるメモリ

容量内のパブリッシュされたデータセットに対して要求が発行されると、そのデータセットが永続ストレージからメモリに読み込まれます (これはイメージの読み込みとも呼ばれます)。 データセットをメモリに読み込まれたままにすると、このデータセットに対するそれ以降のクエリに速く応答できるようになります。 データセットをメモリに読み込まれたままにするために必要なメモリに加えて、レポートのクエリおよびデータセットの更新でも追加のメモリが消費されます。

### <a name="dataset-memory-estimation"></a>データセットのメモリの推定

メモリへのデータセットの読み込みを試みるとき、Power BI は要求されたコマンドを完了するためにデータセットが必要とするメモリの量を推定します。 メモリ内のデータセットのサイズは、ディスクに保存されるときより大きくなる傾向があります。 データセットの更新の間には、アイドル時に必要なメモリの量の少なくとも 2 倍のメモリ容量が必要になります。

### <a name="overcommitting-capacity-eviction-and-reloading-of-datasets"></a>容量のオーバーコミット、削除、データセットの再読み込み

Power BI Premium には、容量をオーバーコミットできる利点があります。 たとえば、メモリが保持できる容量より多くのデータセットをパブリッシュすることができます。 容量にパブリッシュされるデータセットが、容量に収まらないほど多くのメモリを必要とする場合、データセットの一部は永続ストレージに分けて格納されます。 永続ストレージは、各容量に関連付けられている 100 TB のストレージの一部です。

それでは、どのようなデータセットがメモリに保持され、他のデータセットはどうなるのでしょうか。 前に説明したように、データセットに対して要求が発行されると、データセットはメモリに読み込まれます (イメージの読み込み)。 要求は、レポート クエリでも更新操作でもかまいません。

容量をオーバーコミットできるため、容量ではメモリ不足が発生する可能性もあります。 容量でメモリ不足が発生すると (新しいデータセットを読み込む必要があるため、または読み込まれたデータセットに対するクエリによりメモリ要件が増えたため)、ノードは容量のメモリを占有している "*1 つまたは複数のデータセットを削除*" します。 非アクティブな (つまり、クエリ/更新操作が現在実行されていない) データセットが最初に削除され、削除の順序は LRU ("最も長く使われていない") 方式になります。 削除されたデータセットに対して新しいコマンドが発行されると、サービスはそのデータセットのメモリへの再読み込みを試み、他のデータセットが削除される可能性があります。 この動作により、容量はメモリが保持できる量よりはるかに多くのデータセットを提供できるため、いっそう効率的な利用が可能になります。

メモリへのデータセットの読み込みは、かなりコストのかかる操作です。 データセットのサイズに応じて、小さいデータセットで数秒程度、10 GB といった大きいデータセットになると数十秒から場合によっては分単位の時間がかかることがあります。 Premium 容量は、最も長く使われていないデータセットを可能な限り長くメモリに保持することで、容量の読み込みが必要な回数を最小限に抑えようとします。 追加のメモリが必要になると、一部のデータセットを削除する必要があり、システムはユーザー エクスペリエンスへの影響が最も小さいデータセットの選択を試みます。 追加のメモリが必要になると、一部のデータセットを削除する必要があり、システムはユーザー エクスペリエンスへの影響が最も小さいデータセットの選択を試みます。 たとえば、システムは過去数分以内に頻繁に使われたデータセットの削除は避けます。このようなデータセットはすぐに再び必要になる可能性があるためです。

削除プロセス自体は高速な操作です。 削除の時点でデータセットが活発に使われていない場合、削除によってユーザーが気付くような大きな影響はありません。 しかし、多数のデータセットが同時に活発に使われていて、そのすべてを保持するのに十分なメモリがない場合は、多くの削除が発生する可能性があります。 これにより、"スラッシング" と呼ばれる状況が発生することがあります。そうなると、データセットの削除と再読み込みが常に行われており、ユーザーは応答時間が長くなりパフォーマンスが低下したことに気付くことがあります。

### <a name="dataset-refresh-memory-requirement-competing-with-an-active-dataset-memory-requirement"></a>アクティブなデータセットのメモリ要件と競合するデータセット更新のメモリ要件

データセットは、スケジュールに基づいて、またはユーザーがオンデマンドで更新できます。 前に説明したように、完全な更新に必要なメモリは、読み込まれていてアイドル状態のデータセットのメモリ サイズの少なくとも 2 倍になります。 更新が開始する前に、更新に必要なメモリの量が推定されます。 必要な総メモリ量が、容量で使用可能なメモリ量を超える場合、一部のデータセットが削除されます。 削除の候補は、最も長く使われていないデータセットの順に選択されます。つまり、サービスは、最近使用されたデータセットをできるだけ多くメモリ内に保持しようとします。

削除しても必要なメモリを確保できない場合、更新は再試行のためにキューに格納されます。 サービスは、更新が成功するまで、または新しい更新アクションが開始するまで再試行します。

容量内のいずれかのデータセットに対して対話型クエリが発行され、実行中の更新のために十分なメモリを使用できない場合、その要求は失敗し、ユーザーによって再試行される必要があります。

## <a name="cpu-resource-management-in-premium-capacity"></a>Premium 容量における CPU リソースの管理

CPU リソースを主に消費するのは次の 2 つです。

- レポートからのクエリ
- 更新 (処理)

### <a name="queries-from-reports"></a>レポートからのクエリ

レポートのクエリは、容量の CPU リソースを消費します。 レポートに効率の悪いクエリがいくつも含まれる場合、または多数の同時ユーザーがいる場合は、大量の CPU リソースが消費されて、既存の容量では負荷を処理するのに十分ではない可能性があります。

### <a name="refresh-parallelization-policy"></a>更新並列化ポリシー

データセットの更新を制限する可能性があるリソースはメモリだけではありません。 サーバー上の仮想コアの数も要因になることがあります。 各更新操作には一定の数の仮想コアが必要なので、同時に実行できる更新の数には制限があります。 次の表は SKU ごとの制限を詳しく示したものです。 これらの制限を超えた分の更新は、キューに登録されます。

 | SKU  | バックエンド v コア数  | モデル更新並列処理   |
 | --- | --- | --- |
 | A1  | 0.5  | 1  |
 | A2  | 1  | 2  |
 | A3  | 2  | 3  |
 | A4  | 4  | 6  |
 | A5  | 8  | 12  |
 | A6  | 16  | 24  |
 | EM1  | 0.5  | 1  |
 | EM2  | 1  | 2  |
 | EM3  | 2  | 3  |
 | P1  | 4  | 6  |
 | P2  | 8  | 12  |
 | P3  | 16  | 24  |
 | P4  | 32  | 48  |
 | P5  | 64  | 96  |

 > [!TIP]
> 更新で遅延が発生する場合は、容量でサポートされている並列更新の数を確認してください。

## <a name="example-scenarios"></a>シナリオの例

以下では、いくつかの一般的なシナリオと、サービスによって実行されるアクションを説明します。

 **スケジュールされた 20 件の更新がすべて同時に送信される** – Power BI は、最初の *x* 件の更新を同時に開始しようとします。 *x* の値は、その SKU に対する更新並列化ポリシーによって決定されます。 Power BI が非アクティブなデータセット (最近使われていないデータセット) を削除することで十分なメモリを確保できない場合、*x* 件の更新がすべて同時に開始することはありません。 開始できない更新は、開始できるようになるまでキューに格納されます。

 **2 件の更新が同時に実行し、メモリは 1 件が完了するのに十分な量しかない** – 完了できる更新は開始します。 もう一つの更新は後で再試行されます。

 **複数のデータセットの更新中に、多数のデータセットに対するクエリが行われる** – 十分なメモリを使用できない場合、Power BI は対話型クエリを優先させて、アクティブな更新の停止を試みます。 これにより、更新のパフォーマンスは低下します。

 **データセットに必要なメモリの量が多すぎて、現在の容量サイズでは更新できない** – 更新は失敗します。 削除によるメモリ取得の試みは行われません。

 **メモリに大きなスパイクを持つ 1 つのデータセットを更新する** – 非アクティブなデータセットを削除して取得できるメモリの量よりスパイクの方が大きい場合は、スパイクを処理するのに十分なメモリが得られるまで、更新は再試行されます。

 **すべての非アクティブなデータセットと更新を削除しても十分なメモリを取得できないデータセットに対してクエリが実行される** – そのクエリは失敗します。 この種のワークロード要件の場合は、容量を購入する必要があります。

## <a name="troubleshooting-and-testing"></a>トラブルシューティングとテスト

レポートが遅い場合、または応答しない場合は、レポートのユーザーを 1 人だけにしてテストを始めます。 その後、同時実行ユーザーの負荷を増やしながら、限界を見極めます。 多くの場合、DAX (レポート クエリ) をチューニングすると、レポートのパフォーマンスが大幅に変化することがあります (容量でサポートされる同時実行ユーザーの数が増えます)。

Azure で Power BI Embedded の容量を使って異なる SKU をテストし、予想されるワークロードに対する最適な Premium SKU を決定します。 Power BI Embedded の A4 SKU は P1 と、A5 は P2 と、A6 は P3 とそれぞれ同等です。 Azure portal でスケールアップおよびスケールダウンすることで、簡単に SKU を切り替えることができます。 ワークロードに最適な SKU が見つかり、テストが完了したら、SKU を削除できます。

場合によっては、モデルの PBIX ファイルをコンピューターで開き、メモリと CPU の消費量を調べると、問題について多くの情報が得られます。 非常に大きいモデルにはこの方法は使えませんが、小さいモデルの場合は、お使いのコンピューターからモデルを開き、更新し、クエリを行ってみてください。 モデルを開いたときに消費されるモデル サイズ、メモリ、CPU を確認します。 更新とクエリを実行します。 タスク マネージャーを使って、ローカル PBIX ファイルの CPU とメモリの消費量を調べます。 場合によっては、コンピューター自体のこれらのメトリックにより、P1/P2 のような低い Premium 容量では目的のソリューションで動作しないことがわかる可能性があります。
